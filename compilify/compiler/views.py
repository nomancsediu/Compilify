"""
API Views for Compilify Lexical Analyzer

This module provides REST API endpoints for lexical analysis functionality.

Author: Compilify Team
Version: 1.0.0
"""

import json
import logging
from typing import Dict, Any

from rest_framework.decorators import api_view
from rest_framework.response import Response
from django.views.decorators.csrf import csrf_exempt
from django.http import JsonResponse

from .lexer import Lexer

# Configure logging
logger = logging.getLogger(__name__)


@csrf_exempt
@api_view(['POST'])
def lexical_analysis(request) -> JsonResponse:
    """
    Perform lexical analysis on the provided source code.
    
    This endpoint accepts source code and returns a list of tokens
    generated by the lexical analyzer.
    
    Args:
        request: HTTP request containing source code in JSON format
        
    Returns:
        JsonResponse: JSON response containing tokens or error message
        
    Request Format:
        {
            "code": "x + 5 * (y - 2);"
        }
        
    Success Response:
        {
            "success": true,
            "tokens": [
                {"type": "IDENTIFIER", "value": "x", "position": 0},
                {"type": "PLUS", "value": "+", "position": 2},
                ...
            ]
        }
        
    Error Response:
        {
            "success": false,
            "error": "Error message"
        }
    """
    try:
        # Extract code from request
        if hasattr(request, 'data') and request.data:
            code = request.data.get('code', '')
        else:
            data = json.loads(request.body.decode('utf-8'))
            code = data.get('code', '')
        
        # Validate input
        if not isinstance(code, str):
            return Response({
                'success': False,
                'error': 'Code must be a string'
            }, status=400)
        
        # Perform lexical analysis
        lexer = Lexer()
        tokens = lexer.tokenize(code)
        
        logger.info(f"Successfully tokenized code with {len(tokens)} tokens")
        
        return Response({
            'success': True,
            'tokens': tokens,
            'token_count': len(tokens)
        })
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON decode error: {str(e)}")
        return Response({
            'success': False,
            'error': 'Invalid JSON format'
        }, status=400)
        
    except SyntaxError as e:
        logger.warning(f"Syntax error in code: {str(e)}")
        return Response({
            'success': False,
            'error': f'Syntax Error: {str(e)}'
        }, status=400)
        
    except Exception as e:
        logger.error(f"Unexpected error in lexical analysis: {str(e)}")
        return Response({
            'success': False,
            'error': 'Internal server error occurred during lexical analysis'
        }, status=500)













